{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OTlmTphz6SZWuKNrjuV7Up5uiyekyE67","timestamp":1721149549510},{"file_id":"1DXc65Hr98IJPHgr8yM9DQjF5O_qfRbN1","timestamp":1720623389333},{"file_id":"1NKuRsr1w4Y8F-8Mp0n-eUvYJSzNiqOMb","timestamp":1719764535977}],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyO24POZrwh85AuyT6BASraT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1nsmgkuO1Pa","executionInfo":{"status":"ok","timestamp":1725109449742,"user_tz":-180,"elapsed":22662,"user":{"displayName":"Cparlak","userId":"09980992329103050048"}},"outputId":"1a180942-b7e5-44ef-a0a1-b1f5c1e4aba5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","source":["from __future__ import print_function\n","## Package\n","import tensorflow as tf\n","\n","import IPython.display as ipd\n","# import librosa\n","# import librosa.display\n","import numpy as np\n","import pandas as pd\n","from pandas import DataFrame\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","from matplotlib.collections import QuadMesh\n","import plotly.graph_objs as go\n","import plotly.offline as py\n","import plotly.tools as tls\n","import seaborn as sn\n","import scipy.io.wavfile\n","py.init_notebook_mode(connected=True)\n","\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n","from tensorflow.keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","\n","import scipy.io as sio\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from scipy.io import arff\n","## Python\n","import random as rn\n","import sys\n","from sklearn import preprocessing\n","import glob\n","import os\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import confusion_matrix\n","\n","# imports\n","# import os\n","# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"\n","import my_models\n","\n","model_list1=['mini_nvidia_model','nvidia_model','sVGG','VGG16','VGG19','ResNet v2','ResNet v1','ConvSpeechModel','RNNSpeechModel','attRNNSpeechModel']\n","alist  = pd.DataFrame(columns=['Model','Train', 'Test', 'Acc', 'Loss','Precision','Recall','F1','Kappa','B_Accuracy','Best_Acc3'])\n","alist2 = pd.DataFrame(columns=['Model','Train', 'Test', 'Acc', 'Loss'])\n","\n","alist3 = pd.DataFrame(columns=['Model','Train', 'Test', 'Acc', 'Loss'])\n","\n","best_acc=0\n","best_loss=1000000000;\n","best_acc2=0\n","best_acc3=0\n","\n","class PerformancePlotCallback(keras.callbacks.Callback):\n","    def __init__(self, x_test, y_test, model1, alist1, best_acc1):\n","        self.x_test = x_test\n","        self.y_test = y_test\n","        self.model = model1\n","        self.alist=alist1\n","        self.best_acc=best_acc1\n","        self.value1 = 1\n","        self.value2 = 2\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        print('Evaluating Model...')\n","        score=self.model.evaluate(self.x_test,self.y_test,verbose=0)\n","        if score[1]>self.best_acc:\n","            self.best_acc=score[1]\n","        self.alist.loc[epoch]=[str1,tail1+'_'+modelstr2,self.best_acc,score[1], score[0]]\n","        print('Test  acc: ', score[1])\n","        print('Test loss: ', score[0])\n","        print('Best acc: ', self.best_acc)\n","        global best_acc3\n","        best_acc3=self.best_acc\n","\n","        # return [self.value1, self.value2]\n","        # y_pred = self.model.predict(self.x_test)\n","        # fig, ax = plt.subplots(figsize=(8,4))\n","        # plt.scatter(y_test, y_pred, alpha=0.6,\n","        #     color='#FF0000', lw=1, ec='black')\n","        # lims = [0, 5]\n","        # plt.plot(lims, lims, lw=1, color='#0000FF')\n","        # plt.ticklabel_format(useOffset=False, style='plain')\n","        # plt.xticks(fontsize=18)\n","        # plt.yticks(fontsize=18)\n","        # plt.xlim(lims)\n","        # plt.ylim(lims)\n","        # plt.tight_layout()\n","        # plt.title(f'Prediction Visualization Keras Callback - Epoch: {epoch}')\n","        # plt.savefig('model_train_images/'+self.model_name+\"_\"+str(epoch))\n","        # plt.close()\n","\n","# Plot the confusion matrix\n","def plot_advanced_confusion_matrix(fname1, cm, classes, normalize=False, title='Karmaşıklık Matrisi',\n","                                   cmap='Blues', fontsize=16, label_fontsize=14):\n","\n","    \"\"\"\n","    This function plots an advanced confusion matrix with additional features.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    fig, ax = plt.subplots(figsize=(10, 8))\n","    sn.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd', cmap=cmap, cbar_kws={'label': 'Ölçek'}, ax=ax,\n","                annot_kws={\"size\": fontsize})\n","\n","    ax.set_xlabel('Tahmin', fontsize=label_fontsize)\n","    ax.set_ylabel('Gerçek', fontsize=label_fontsize)\n","    ax.set_title(title, fontsize=label_fontsize + 2)\n","\n","    # Set tick labels\n","    ax.set_xticklabels(classes, rotation=45, ha=\"right\", fontsize=label_fontsize)\n","    ax.set_yticklabels(classes, rotation=0, fontsize=label_fontsize)\n","\n","    # Add legend\n","    plt.legend([], [], frameon=False)\n","    fig.tight_layout()\n","    # plt.show()\n","    plt.savefig(fname1)\n","\n","nrows=127  # number of rows of feature vectors, columns are auto-adjusted\n","batch_size1 = 16\n","epoch1 = 100\n","test_size1=0.30\n","lr1=0.001;\n","factor1=0.90\n","patience1=10\n","acf='relu'\n","n1=6 # for resnet\n","\n","i=1\n","# np.random.seed(1234)\n","# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1 )\n","# sess = tf.compat.v1.Session( graph=tf.compat.v1.get_default_graph(), config=session_conf )\n","# tf.compat.v1.keras.backend.set_session(sess)\n","#-----------------------------Keras reproducibility------------------#\n","# SEED = 1234\n","\n","# tf.set_random_seed(SEED)\n","# os.environ['PYTHONHASHSEED'] = str(SEED)\n","# np.random.seed(SEED)\n","# rn.seed(SEED)\n","\n","# session_conf = tf.ConfigProto(\n","#     intra_op_parallelism_threads=1,\n","#     inter_op_parallelism_threads=1\n","# )\n","# sess = tf.Session(\n","#     graph=tf.get_default_graph(),\n","#     config=session_conf\n","# )\n","# K.set_session(sess)\n","#-----------------------------------------------------------------#\n","#list1=glob.glob(\"E:/PhD/thesis/efb/spc/x/*.npy\")\n","#list1=glob.glob(\"E:/PhD/thesis/emo/emo2/xx/*.npy\")\n","#list1=glob.glob(\"E:/PhD/thesis/emo/efb2/x/*.npy\")\n","#list1=glob.glob(\"E:/PhD/thesis/afb/afb/400-160/x/x/*.npy\")\n","#list1=glob.glob(\"E:/PhD/thesis/emo/emo1/x/*.npy\")\n","#list1=glob.glob(\"E:/PhD/articles/Arabian/converted labels/*.npy\")\n","# list1=glob.glob(\"E:/PhD/thesis/afb/afb/400-160/x/fs/*.npy\")\n","\n","# path1=\"E:/PhD/articles/EFB/springer/data/iemo impro aug/\"\n","# path1=\"E:/PhD/articles/EFB/springer/data/downsampled/\"\n","# path1=\"E:/PhD/articles/EFB/springer/data/iemo impro aug/\"\n","# path1=\"E:/PhD/thesis/afb/data/dergi2/\"\n","path1=\"/content/gdrive/My Drive/spc/\"\n","\n","list1=[\n","       'mnist speakers_efb_b12_x5__emp3_d_512_256_100_norm_type_1.npy',\n","       'mnist speakers_efb_b13_x5__emp3_d_512_256_100_norm_type_1.npy',\n","       'mnist speakers_mfcc___emp3_d_512_256_100_norm_type_1.npy',\n","\n","        # 'mnist_efb_b12_x5__emp3_d_512_256_100_norm_type_1.npy',\n","        # 'mnist_efb_b13_x5__emp3_d_512_256_100_norm_type_1.npy',\n","        # 'mnist_mfcc___emp3_d_512_256_100_norm_type_1.npy',\n","    # 'spc digits_efb_b12_x5__emp3_d_512_256_100_norm_type_1.npy',\n","    # 'spc digits_mfcc___emp3_d_512_256_100_norm_type_1.npy',\n","    # 'spc digits_efb_b13_x5__emp3_d_512_256_100_norm_type_1.npy',\n","\n","    # '3mix_efb_b12_x5__emp3_d_512_256_100_norm_type_1.npy',\n","    # '3mix_efb_b13_x5__emp3_d_512_256_100_norm_type_1.npy',\n","    # '3mix_mfcc___emp3_d_512_256_100_norm_type_1.npy',\n","\n","    # 'fkd_efb_b12_x5__emp3_d_512_256_100_norm_type_1.npy',\n","    # 'fkd_mfcc___emp3_d_512_256_100_norm_type_1.npy',\n","    # 'fkd_efb_b13_x5__emp3_d_512_256_100_norm_type_1.npy',\n","\n","    # 'ti_efb_b13_x4__emp3_d_400_160_100_norm_type_1.npy',\n","    # 'ti_mel___emp3_d_400_160_100_norm_type_1.npy',\n","    # 'ti_mfcc___emp3_d_400_160_100_norm_type_1.npy',\n","\n","    # 'hd_efb_b13_x4__emp3_d_400_160_100_norm_type_1.npy',\n","    # 'hd_mel___emp3_d_400_160_100_norm_type_1.npy',\n","    # 'hd_mfcc___emp3_d_400_160_100_norm_type_1.npy',\n","\n","    # 'fs_efb_b13_x4__emp3_d_400_160_100_norm_type_1.npy',\n","    # 'fs_mel___emp3_d_400_160_100_norm_type_1.npy',\n","    # 'fs_mfcc___emp3_d_400_160_100_norm_type_1.npy',\n","\n","]\n","\n","lr_list1=(0.001,0.01,0.1)\n","test_size_list1=(0.30,0)\n","cm1=0\n","for cm1 in range(1):\n","    lr1=lr_list1[cm1]\n","    # test_size1=test_size_list1[cm1]\n","    print(test_size1)\n","    ct1=0;\n","    for st in list1:\n","        ct1=ct1+1\n","        # if ct1>0:\n","        #     nrows=127\n","        #     nclasses=18\n","\n","#    df=arff.loadarff(st)\n","        lr1=0.001\n","        print(path1+st)\n","        x=np.load(path1+st)\n","        y=x[:,-1]\n","#    break\n","        x=x[:,:-1]\n","#    break\n","        x[np.isnan(x)] = 0\n","        # x1=x\n","        #    x[~np.all(x == 0, axis=1)]\n","    #    xx=np.any(np.isnan(x))\n","    # normalize each column independently between [0,1]\n","\n","        min_max_scaler = preprocessing.MinMaxScaler()\n","        x= min_max_scaler.fit_transform(x)\n","        # xx=x\n","        # del data\n","        # feature count must be greater than 40 or so for the cnn\n","        # xx=x;\n","        # x=x[:,1:1900]\n","\n","        # exit\n","        a1=x.shape[1]\n","        a2=a1 % nrows\n","        # print(a1)\n","        # print(a2)\n","        if a2!=0:\n","            a2=nrows-a2\n","            c1=np.zeros((x.shape[0],a2),dtype=int)\n","            x=np.concatenate((x,c1),axis=1)\n","        # print(a2)\n","\n","        values, counts = np.unique(y, return_counts=True)\n","        n_classes=len(counts)\n","        ncols=int(x.shape[1]/nrows)\n","        x_train, x_test, y_train, y_test  = sklearn.model_selection.train_test_split(x, y, test_size=test_size1, random_state=1)\n","        # xxx=x_test\n","        # xxxx = x_test.reshape(x_test.shape[0], nrows,ncols)\n","        # del x\n","        # del y\n","        # print(nrows)\n","        # print(ncols)\n","        print('x_train shape:', x_train.shape)\n","        print('x_test shape :', x_test.shape)\n","        print(x_train.shape[0], 'train samples')\n","        print(x_test.shape[0], 'test samples')\n","\n","        # input image dimensions\n","        img_rows, img_cols = nrows, ncols\n","\n","\n","        if K.image_data_format() == 'channels_first':\n","            x_train = x_train.reshape(x_train.shape[0], 1, img_rows,img_cols)\n","            x_test = x_test.reshape(x_test.shape[0], 1, img_rows,img_cols)\n","            input_shape = (1, img_rows,img_cols)\n","        else:\n","            x_train = x_train.reshape(x_train.shape[0], img_rows,img_cols, 1)\n","            x_test = x_test.reshape(x_test.shape[0], img_rows,img_cols, 1)\n","            input_shape = (img_rows,img_cols, 1)\n","\n","        # xxxx=x_train\n","        # convert class vectors to binary class matrices\n","        y_train = y_train-1\n","        y_test = y_test-1\n","        y_test=y_test.astype(int)\n","        y_train = keras.utils.to_categorical(y_train, n_classes)\n","        y_test = keras.utils.to_categorical(y_test, n_classes)\n","\n","        print('x_train shape:', x_train.shape)\n","        print('x_test shape :', x_test.shape)\n","        print(x_train.shape[0], 'train samples')\n","        print(x_test.shape[0], 'test samples')\n","\n","        # np.save(\"x_train25.npy\",x_train)\n","        # np.save(\"x_test25.npy\",x_test)\n","        # np.save(\"y_train25.npy\",y_train)\n","        # np.save(\"y_test25.npy\",y_test)\n","\n","        cm=5\n","        if cm==0:\n","            model, str1 = my_models.mini_nvidia_model(input_shape, n_classes, acf)\n","        # if cm==1:\n","        #     model, str1 = my_models.nvidia_model(input_shape, n_classes, acf)\n","        # if cm==2:\n","        #     model, str1 = my_models.sVGG(input_shape, n_classes, acf)\n","        if cm==3:\n","            model, str1 = my_models.VGG16(input_shape, n_classes, acf)\n","        if cm==4:\n","            model, str1 = my_models.VGG19(input_shape, n_classes, acf)\n","        if cm==5:\n","            model, str1 = my_models.resnet_v2(input_shape, n_classes, acf, n1)\n","        # str1='ResNet20'\n","        # if cm==6:\n","        #     model, str1 = my_models.ConvSpeechModel(input_shape, n_classes, acf)\n","        # if cm==7:\n","        #     model, str1 = my_models.RNNSpeechModel(input_shape, n_classes, acf)\n","        # if cm==8:\n","        #     model, str1 = my_models.attRNNSpeechModel(input_shape, n_classes, acf)\n","\n","#        model.compile(loss='categorical_crossentropy', optimizer=optimizer1, metrics=['accuracy'])\n","            #  optimizer = Adam(lr=1e-4)\n","        #    optimizer=keras.optimizers.RMSprop(lr=0.0001) #, rho=0.9, epsilon=None, decay=0.0)\n","        #    optimizer=keras.optimizers.Adadelta() #, epsilon=None, decay=0.0)\n","        #  optimizer=keras.optimizers.Adagrad(lr=0.001) #, epsilon=None, decay=0.0)\n","        #  optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","        #  optimizer=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n","        #  optimizer=keras.optimizers.Nadam(lr=0.0001) #, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n","        # Model Training\n","        #    lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=factor1, patience=patience1, min_lr=0.000000001, verbose=1)\n","        # Please change the model name accordingly.\n","        #    mcp_save = ModelCheckpoint('model/aug_noiseNshift_2class2_np.h5', save_best_only=True, monitor='val_loss', mode='min')\n","        #optimizer = Adam(lr=1e-4)\n","        # model.summary()\n","\n","        # Prepare model saving directory.\n","#        save_dir = os.path.join(os.getcwd(), 'saved_models')\n","#        model_name = 'best_model'+ modelstr1\n","#        if not os.path.isdir(save_dir):\n","#            os.makedirs(save_dir)\n","#        filepath = os.path.join(save_dir, model_name)\n","        # Prepare callbacks for model saving and for learning rate adjustment.\n","#        checkpoint = ModelCheckpoint(filepath=filepath,\n","#                                     monitor='val_acc',\n","#                                     verbose=1,\n","#                                     save_best_only=True)\n","\n","\n","        # optimizer1 = keras.optimizers.SGD(lr=lr1, momentum=0.0, decay=0.0, nesterov=True)\n","        # opt_name='sgd';\n","        # lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=factor1, patience=patience1, min_lr=0.000000001, verbose=1)\n","        # lr_scheduler = LearningRateScheduler(lr_schedule)\n","        # lr_reduce2 = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n","        # callbacks = [checkpoint, lr_reduce, lr_scheduler]\n","        # callbacks = [lr_reduce]\n","\n","\n","        optimizer1=keras.optimizers.Adam(learning_rate=lr1, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","        opt_name='adam';\n","\n","        head1, tail1 = os.path.split(path1+st)\n","        modelstr1=str(st)+'_'+str(lr1)+'_'+str(factor1)+'_'+str(patience1)+'_'+str(nrows)+'_'+str(epoch1)+'_'+str(batch_size1)+'_'+acf+'_'+str(test_size1)\n","        modelstr2=str1+modelstr1+'_'+opt_name\n","\n","        rlrop1 = ReduceLROnPlateau(monitor='loss', factor=factor1, patience=patience1, min_lr=0.000000001, verbose=1)\n","\n","        model.compile(loss='categorical_crossentropy', optimizer=optimizer1, metrics=['accuracy'])\n","        # perf1 = PerformancePlotCallback(x_test, y_test,model,alist3,best_acc)\n","\n","        # model.summary();\n","        history=model.fit(x_train, y_train,\n","                      batch_size=batch_size1,\n","                      epochs=epoch1,\n","                      validation_split=0.2,\n","                      # validation_data=(x_test, y_test),\n","\n","                      shuffle=True,\n","                      callbacks=[rlrop1]\n","                      # callbacks=[perf1,rlrop1]\n","                      )\n","        score = model.evaluate(x_test, y_test, batch_size=batch_size1, verbose=1)\n","            # history=model.fit(x_train, y_train, batch_size = batch_size1, epochs=epoch1,  validation_data=(x_test, y_test), callbacks=[lr_reduce])\n","            # score = model.evaluate(x_test, y_test, verbose=0)\n","        # modelstr1='cnn_'+str(lr1)+'_'+str(factor1)+'_'+str(patience1)+'_'+str(nrows)+'_'+str(epoch1)+'_'+str(batch_size1)+'_'+acf+'_'+str(test_size1)\n","        # modelstr2=model_list1[cm]+'_'+modelstr1+'_'+opt_name\n","\n","        print('Test accuracy:', score[1])\n","        print('Test loss:', score[0])\n","        head1, tail1 = os.path.split(path1+st)\n","\n","    # Plotting the Train Valid Loss Graph\n","        r1=8\n","        c1=6\n","        f1=16\n","        linew1=3\n","        plt.clf()\n","        plt.figure(figsize=(r1,c1))\n","        plt.rcParams.update({'font.size': f1})\n","        plt.plot(history.history['loss'],linewidth=linew1)\n","        plt.plot(history.history['val_loss'],linewidth=linew1)\n","        plt.title('Model Loss')\n","        plt.xlabel('epoch')\n","        plt.ylabel('loss')\n","        plt.legend(['train', 'test'])\n","    #    plt.legend(['training', 'test'], loc='upper left')\n","    #    plt.show()\n","        plt.savefig(head1+'/aloss_'+tail1+'_'+modelstr2+'.png')\n","        # np.save(head1+'/aloss_'+tail1+'_'+modelstr2+'.npy', history.history['loss'])\n","        # np.save(head1+'/aloss_val_'+tail1+'_'+modelstr2+'.npy', history.history['val_loss'])\n","\n","        plt.clf()\n","        plt.figure(figsize=(r1,c1))\n","        plt.rcParams.update({'font.size': f1})\n","        plt.plot(history.history['accuracy'],linewidth=linew1)\n","        plt.plot(history.history['val_accuracy'],linewidth=linew1)\n","        plt.title('Model Accuracy')\n","        plt.xlabel('epoch')\n","        plt.ylabel('accuracy')\n","        plt.legend(['train','test'])\n","    #    plt.show()\n","        plt.savefig(head1+'/acc_'+tail1+'_'+modelstr2+'.png')\n","        # np.save(head1+'/acc_'+tail1+'_'+modelstr2+'.npy', history.history['accuracy'])\n","        # np.save(head1+'/acc_val_'+tail1+'_'+modelstr2+'.npy', history.history['val_accuracy'])\n","    #    plt.clf()\n","        print(head1+'/aloss_'+tail1+'_'+modelstr2+'.png')\n","\n","        y_pred = model.predict(x_test, batch_size = batch_size1)\n","        y_test1=np.argmax(y_test, axis=1)\n","    #    y_test1=y_test1.tolist()\n","        y_pred1 = np.argmax(y_pred, axis=1)\n","    #    y_pred1 = y_pred1.tolist()\n","        # predict probabilities for test set\n","        yhat_probs = y_pred\n","        # predict crisp classes for test set\n","        # yhat_classes = model.predict_classes(x_test, verbose=0)\n","        predict_x=model.predict(x_test)\n","        yhat_classes=np.argmax(predict_x,axis=1)\n","\n","        # reduce to 1d array\n","        yhat_probs = yhat_probs[:, 0]\n","    #    yhat_classes = yhat_classes[:, 0]\n","        # accuracy: (tp + tn) / (p + n)\n","        accuracy = accuracy_score(y_test1, yhat_classes)\n","        print('Accuracy: %f' % accuracy)\n","        # balanced accuracy: (tp + tn) / (p + n)\n","        b_accuracy = balanced_accuracy_score(y_test1, yhat_classes)\n","        print('Balanced Accuracy: %f' % b_accuracy)\n","        # precision tp / (tp + fp)\n","        precision = precision_score(y_test1, yhat_classes,average='weighted')\n","        print('Precision: %f' % precision)\n","        # recall: tp / (tp + fn)\n","        recall = recall_score(y_test1, yhat_classes,average='weighted')\n","        print('Recall: %f' % recall)\n","        # f1: 2 tp / (2 tp + fp + fn)\n","        f1 = f1_score(y_test1, yhat_classes,average='weighted')\n","        print('F1 score: %f' % f1)\n","        # kappa\n","        kappa = cohen_kappa_score(y_test1, yhat_classes)\n","        print('Cohens kappa: %f' % kappa)\n","        # ROC AUC\n","    #    auc = roc_auc_score(y_test1, yhat_probs)\n","    #    print('ROC AUC: %f' % auc)\n","        # confusion matrix\n","        conf_mat = confusion_matrix(y_test1, yhat_classes)\n","        df=pd.DataFrame(data=conf_mat[0:,0:], index=[i for i in range(conf_mat.shape[0])], columns=['f'+str(i) for i in range(conf_mat.shape[1])])\n","        df.to_excel(head1+'/aconf_mat_'+tail1+'_'+modelstr2+'.xlsx')\n","        print(conf_mat)\n","#        np.savetxt(head1+'/conf_mat_'+tail1+'_'+modelstr1+'.csv', conf_mat, '%s', delimiter=\",\")\n","\n","#        labels=['ANGRY','HAPPY','NEUTRAL','SAD']\n","#        print('_test_data_class: test function with y_test (actual values) and predictions (predict)')\n","#        _test_data_class(y_test1,y_pred1)\n","        # alist.loc[i]=[str1,tail1,'',score[1],score[0],precision,recall,f1,kappa,'']\n","        alist.loc[i]=[str1,tail1+'_'+modelstr2,'',score[1],score[0],precision,recall,f1,kappa,b_accuracy,best_acc3]\n","\n","        i=i+1\n","    #    np.savetxt(head1+'/alist_'+'_'+modelstr1+'.csv', alist, '%s', delimiter=\"/t\")\n","        del x_train\n","        del x_test\n","\n","        # # # Generate the confusion matrix\n","        # cm = confusion_matrix(y_test1, yhat_classes)\n","        # # cm_normalized = confusion_matrix(true_labels, predicted_labels, normalize='true')\n","\n","        # # Class names for the confusion matrix\n","        # class_names = ['Sınıf 1', 'Sınıf 2', 'Sınıf 3', 'Sınıf 4', 'Sınıf 5', 'Sınıf 6', 'Sınıf 7', 'Sınıf 8', 'Sınıf 9', 'Sınıf 10']\n","        # # ,'Sınıf 11', 'Sınıf 12', 'Sınıf 13', 'Sınıf 14', 'Sınıf 15', 'Sınıf 16', 'Sınıf 17', 'Sınıf 18']\n","\n","        # # Plot the confusion matrix without normalization\n","        # cfname1=head1+'/aconf_mat_'+tail1+'_'+modelstr2+'.png'\n","        # plot_advanced_confusion_matrix(fname1=cfname1, cm=cm, classes=class_names, title='Yeni Filtreler Karmaşıklık Matrisi')\n","\n","\n","        # # Plot the normalized confusion matrix\n","        # # plot_advanced_confusion_matrix(cm, classes=class_names, normalize=True, title='Normalize Karmaşıklık Matrisi')\n","\n","\n","        alist.to_excel(head1+'/alist_'+'_'+tail1+'_'+modelstr2+'.xlsx')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":700},"id":"TvkfCPUxO2Vy","outputId":"d6cf792e-bcf9-4f23-e9c5-f77d5ce1d857","executionInfo":{"status":"error","timestamp":1725109834821,"user_tz":-180,"elapsed":121116,"user":{"displayName":"Cparlak","userId":"09980992329103050048"}}},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.3\n","/content/gdrive/My Drive/spc/mnist speakers_efb_b12_x5__emp3_d_512_256_100_norm_type_1.npy\n","x_train shape: (21000, 1524)\n","x_test shape : (9000, 1524)\n","21000 train samples\n","9000 test samples\n","x_train shape: (21000, 127, 12, 1)\n","x_test shape : (9000, 127, 12, 1)\n","21000 train samples\n","9000 test samples\n","Epoch 1/100\n","\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.3249 - loss: 3.8172 - val_accuracy: 0.8105 - val_loss: 1.4729 - learning_rate: 0.0010\n","Epoch 2/100\n","\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.8605 - loss: 1.2715 - val_accuracy: 0.8645 - val_loss: 1.1304 - learning_rate: 0.0010\n","Epoch 3/100\n","\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.9321 - loss: 0.8590 - val_accuracy: 0.9214 - val_loss: 0.8259 - learning_rate: 0.0010\n","Epoch 4/100\n","\u001b[1m 165/1050\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9602 - loss: 0.6841"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-739f76c777c8>\u001b[0m in \u001b[0;36m<cell line: 224>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# model.summary();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         history=model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m    386\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}