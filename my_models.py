from __future__ import print_function
## Package
import IPython.display as ipd
# import librosa
# import librosa.display
import matplotlib.pyplot as plt
import seaborn as sn
import numpy as np
import pandas as pd
import plotly.graph_objs as go
import plotly.offline as py
import plotly.tools as tls
import seaborn as sn
import scipy.io.wavfile
import tensorflow as tf
py.init_notebook_mode(connected=True)

import matplotlib.font_manager as fm
from matplotlib.collections import QuadMesh

from tensorflow import keras
from IPython import display
#from jiwer import wer
from tensorflow.keras import layers as L
from tensorflow.keras import layers

# from keras_self_attention import SeqSelfAttention
# from attention import Attention

import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping
from tensorflow.keras.callbacks import  History, ReduceLROnPlateau, CSVLogger
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, Dropout, Reshape, Activation, BatchNormalization
from tensorflow.keras.layers import Conv2D, MaxPooling2D,TimeDistributed
from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, AveragePooling2D, Input, Flatten, LSTM, GRU, Bidirectional
from tensorflow.keras import backend as K
from tensorflow.keras.utils import plot_model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import *
from tensorflow.keras.models import * 
import scipy.io as sio
import sklearn
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from scipy.io import arff
## Python
import random as rn
import sys
from sklearn import preprocessing
import glob
import os

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
# from keras.layers.wrappers import TimeDistributed
from keras.layers import SimpleRNN, LSTM, GRU
from keras.layers import ConvLSTM2D

# data_shape=(samples,rows,cols)
# input_shape=(rows, cols)
# model = Sequential()
# model.add(TimeDistributed(Dense(10), input_shape=(5, 2)))
# model.add(LSTM(5, return_sequences=True))
# model.add(LSTM(5, return_sequences=True))
# model.add(TimeDistributed(Dense(1)))
# model.compile(loss='mse', optimizer='adam')

# model.fit(X,Y, nb_epoch=4000)

# model.predict(X)
def cnnlstm2(trainX, trainy, testX, testy):
	# define model
	verbose, epochs, batch_size = 0, 25, 64
	n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]
	# reshape into subsequences (samples, time steps, rows, cols, channels)
	n_steps, n_length = 4, 32
	trainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))
	testX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))
	# define model
	model = Sequential()
	model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))
	model.add(Dropout(0.5))
	model.add(Flatten())
	model.add(Dense(100, activation='relu'))
	model.add(Dense(n_outputs, activation='softmax'))
	model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
	# fit network
	model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)
	# evaluate model
	_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)
	return accuracy

# By today, there is a built-in reshape layer in Keras.
# Searching the problem on Stackoverflow brings up a similar question, the accepted answer suggests 
# using the built-in layer.
#
# # As a toy example, I would like to classify MNIST with a combination of Conv-Layers and an LSTM.
# # I've sliced the images into four parts and arranged those parts into sequences. Then I've stacked 
# # the sequences.
# # My training data is a numpy array with the shape [60000, 4, 1, 56, 14] where
# #
# #    60000 is the number of samples
# #    4 is the number of timesteps
# #    1 is number of colors, I'm using Theano layout for the image
# #    56 and 14 are width and height
# #
# # Please note: One of the image-slices has the size 14x14 since I've cut the 28x28 image in four parts. 
# # I get a 56 in the shape, because I've created 4 different sequences and stacked them along this axis.

# nb_filters=32
# kernel_size=(3,3)
# pool_size=(2,2)
# nb_classes=10
# batch_size=64


# def get_CRNN_layers( x_in ):
    
#     #timestamps = 32
#     #freq_dim = 256
    
#     x = BatchNormalization()(x_in)
#     x =  Reshape((timesteps, freq_dim,1))(x)
#     x = Conv2D(64,(5,7),padding='same')(x) #was 32
#     x = batch_relu(x)

#     x = Conv2D(64,(3,3),padding='same')(x)
#     x = batch_relu(x)
#     x = MaxPooling2D((1,3))(x)
    
#     x = Conv2D(64,(3,3),padding='same')(x)
#     x = batch_relu(x)
#     x = Conv2D(64,(3,3),padding='same')(x)
#     x = batch_relu(x)

#     x = MaxPooling2D((2,3))(x)
    

#     x = Conv2D(128,(3,3),padding='same')(x)
#     x = batch_relu(x)
#     x = Conv2D(128,(3,3),padding='same')(x)
#     x = batch_relu(x)

#     x = MaxPooling2D((2,3))(x)
    
#     x = Conv2D(128,(3,3),padding='same')(x)
#     x = batch_relu(x)
#     x = Conv2D(128,(3,3),padding='same')(x)
#     x = batch_relu(x)
    
#     # flattening 2nd and 3rd dimensions
#     x = Reshape((16,int(x.shape[-1]) * int(x.shape[-2])))(x)
    
#     x = Bidirectional(CuDNNLSTM(128,return_sequences=False))(x)
#     return x


# model=Sequential()

# model.add(TimeDistributed(
#     Convolution2D(
#         nb_filters, kernel_size[0], kernel_size[1], border_mode="valid"), input_shape=[4, 1, 56,14]))
# model.add(TimeDistributed(Activation("relu")))
# model.add(TimeDistributed(Convolution2D(nb_filters, kernel_size[0], kernel_size[1])))
# model.add(TimeDistributed(Activation("relu")))
# model.add(TimeDistributed(MaxPooling2D(pool_size=pool_size)))
# model.add(TimeDistributed(Flatten()))
# model.add(TimeDistributed(Dropout(0.25)))
# model.add(LSTM(5))
# model.add(Dense(50))
# model.add(Dense(nb_classes))
# model.add(Activation("softmax"))

# from kaggle
# This script demonstrates the use of a convolutional LSTM network.
# This network is used to predict the next frame of an artificially
# generated movie which contains moving squares.

# from keras.models import Sequential
# from keras.layers.convolutional import Conv3D
# from keras.layers import LSTM
# from keras.layers import ConvLSTM2D
# from keras.layers import BatchNormalization
# import numpy as np
# import pylab as plt

# We create a layer which take as input movies of shape
# (n_frames, width, height, channels) and returns a movie
# of identical shape.

# seq = Sequential()
# seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
#                    input_shape=(None, 40, 40, 1),
#                    padding='same', return_sequences=True))
# seq.add(BatchNormalization())

# seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
#                    padding='same', return_sequences=True))
# seq.add(BatchNormalization())

# seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
#                    padding='same', return_sequences=True))
# seq.add(BatchNormalization())

# seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
#                    padding='same', return_sequences=True))
# seq.add(BatchNormalization())

# seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),
#                activation='sigmoid',
#                padding='same', data_format='channels_last'))
# seq.compile(loss='binary_crossentropy', optimizer='adadelta')
# conv_lstm1_ok
# seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,
#         epochs=300, validation_split=0.05)

def cnn_lstm(input_shape, n_classes, acf):
    str1='cnnlstm'
    maxToAdd = 1

    inp = Input(shape=(maxToAdd, input_shape.shape[0], input_shape.shape[1], 1))
    x = TimeDistributed(Conv2D(32, (8, 8), padding='valid', activation=acf))(inp)
    x = TimeDistributed(Conv2D(64, (8, 8), padding='valid', activation=acf))(x)
    x = TimeDistributed(Flatten())(x)
    x = LSTM(units=128, return_sequences=True)(x)
    x = LSTM(units=64, return_sequences=False)(x)
    x = Dropout(.2)(x)
    x = Dense(n_classes)(x)
    model = Model(inp, x)
    return model,str1

def CNN_LSTM2(input_shape, n_classes, acf):
    str1='cnn_lstm2'
    inp = Input(input_shape)
    x = L.Conv2D(32, (3, 3), activation=acf, padding='same')(inp)
    x = L.BatchNormalization()(x)
    x = L.Conv2D(1, (3, 3), activation=acf, padding='same')(x)
    x = L.BatchNormalization()(x)

    # x = Reshape((125, 80)) (x)
    # keras.backend.squeeze(x, axis)
    x = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)
    x = L.Bidirectional(L.LSTM(64, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]
    x = L.Bidirectional(L.LSTM(64))(x)
    x = L.Dense(512, activation=acf)(x)
    x = Dropout(0.5)(x)
    # x = L.Dense(32, activation=acf)(x)
    x = L.Dense(n_classes, activation='softmax')(x)
    model = Model(inp, x)
    return model, str1            

# this works when called directly from the main file
# BatchNormalization may be required
def CNN_LSTM_Att(input_shape, n_classes, acf):
    str1='cnn_lstm_att'
    inp = Input(input_shape)
    x = L.Conv2D(32, (3, 3), activation=acf, padding='same')(inp)
    # x = L.BatchNormalization()(x)
    x = L.Conv2D(32, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.MaxPooling2D(pool_size=(2, 2))(x)
    x = L.Dropout(0.25)(x)

    x = L.Conv2D(64, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.Conv2D(64, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.MaxPooling2D(pool_size=(2, 2))(x)
    x = L.Dropout(0.25)(x)

    x = L.Conv2D(128, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.Conv2D(128, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.MaxPooling2D(pool_size=(2, 2))(x)
    x = L.Dropout(0.25)(x)
    
    # x = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)
    x = Reshape((-1, 128))(x)
    
    # x = L.Bidirectional(LSTM(256, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]
    # x = SeqSelfAttention(attention_activation ='tanh')(x)
    # x = L.Bidirectional(LSTM(128, return_sequences=False))(x)  # [b_s, seq_len, vec_dim]

    x = L.Bidirectional(LSTM(256, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]
    x = L.Bidirectional(LSTM(128, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]
    x = Attention(units=64)(x)
    x = L.Dense(512, activation=acf)(x)
    x = Dropout(0.5)(x)

    x = L.Dense(n_classes, activation='softmax', name='output')(x)
    model = Model(inp, x)

    return model, str1            

def CNN_LSTM_SelfAtt(input_shape, n_classes, acf):
    str1='cnn_lstm_selfatt'
    inp = Input(input_shape)
    x = L.Conv2D(32, (3, 3), activation=acf, padding='same')(inp)
    # x = L.BatchNormalization()(x)
    x = L.Conv2D(32, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.MaxPooling2D(pool_size=(2, 2))(x)
    x = L.Dropout(0.25)(x)

    x = L.Conv2D(64, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.Conv2D(64, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.MaxPooling2D(pool_size=(2, 2))(x)
    x = L.Dropout(0.25)(x)

    x = L.Conv2D(128, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.Conv2D(128, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    x = L.MaxPooling2D(pool_size=(2, 2))(x)
    x = L.Dropout(0.25)(x)
    
    # x = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)
    x = Reshape((-1, 128))(x)
    
    x = L.Bidirectional(LSTM(256, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]
    x = SeqSelfAttention(attention_activation ='tanh')(x)
    x = L.Bidirectional(LSTM(128, return_sequences=False))(x)  # [b_s, seq_len, vec_dim]

    # x = L.Bidirectional(LSTM(256, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]
    # x = L.Bidirectional(LSTM(128, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]
    # x = Attention(units=64)(x)
    x = L.Dense(512, activation=acf)(x)
    x = Dropout(0.5)(x)

    x = L.Dense(n_classes, activation='softmax', name='output')(x)

    model = Model(inp, x)

    return model, str1  
# ECA- Efficient Channel Attention
def ECA(x):
    k_size = 3 
    squeeze = tf.reduce_mean(x,(2,3),keepdims=False)
    squeeze = tf.expand_dims(squeeze, axis=1)
    attn = layers.Conv1D(filters=1,
    kernel_size=k_size,
    padding='same',
    kernel_initializer='random_normal',
    use_bias=False)(squeeze)

    attn = tf.expand_dims(tf.transpose(attn, [0, 2, 1]), 3)
    attn = tf.math.sigmoid(attn)
    scale = x * attn
    return x * attn

def CNN_ECAtt(input_shape, n_classes, acf):
    str1='eca_att'
    inp = Input(input_shape)
    # inp = layers.Input(shape=(input_shape))
    # x1 = layers.Resizing(img_rows, img_cols)(inp)
    # x2 = layers.Rescaling(1./255)(x1)
    x2 = inp
    x3 = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', 
                       padding = 'same', input_shape=(input_shape))(x2)
    x4 = ECA(x3)
    x5 = layers.BatchNormalization(axis=-1)(x4)
    x6 = layers.MaxPool2D(pool_size=(2, 2))(x5)
    x7 = layers.Conv2D(filters=64, kernel_size=(3, 3), 
                       activation='relu', padding = 'same')(x6)
    x8 = ECA(x7)
    x9 = layers.BatchNormalization(axis=-1)(x8)
    x10 = layers.MaxPool2D(pool_size=(2, 2))(x9)
    x11 = layers.Conv2D(filters=128, kernel_size=(3, 3), 
                        activation='relu', padding = 'same')(x10)
    x12 = ECA(x11)
    x13 = layers.BatchNormalization(axis=-1)(x12)
    x14 = layers.MaxPool2D(pool_size=(2, 2))(x13)
    x15 = layers.Conv2D(filters=256, kernel_size=(3, 3), 
                          activation='relu', padding = 'same')(x14)
    x16 = ECA(x15)
    x17 = layers.BatchNormalization(axis=-1)(x16)
    x18 = layers.MaxPool2D(pool_size=(2, 2))(x17)
    y1 = layers.Flatten()(x18)
    y2 = layers.Dense(300, activation='relu')(y1)
    y3 = layers.Dense(150, activation='relu')(y2)
    y4 = layers.Dropout(0.25)(y3)
    y = layers.Dense(4, activation='sigmoid')(y4)   
    
    model_ECA = tf.keras.Model(inp, y)
    model=model_ECA
    return model, str1  
            

def cbam(cbam_feature, ratio=8):
    """Contains the implementation of Convolutional Block Attention Module(CBAM) block.
    As described in https://arxiv.org/abs/1807.06521.
    """
    
    cbam_feature = channel_attention(cbam_feature, ratio)
    cbam_feature = spatial_attention(cbam_feature)
    return cbam_feature

def channel_attention(input_feature, ratio=8):
    
    channel_axis = 1 if K.image_data_format() == "channels_first" else -1
    channel = input_feature.shape[channel_axis]
    
    shared_layer_one = Dense(channel//ratio,
                             activation='relu',
                             kernel_initializer='he_normal',
                             use_bias=True,
                             bias_initializer='zeros')
    shared_layer_two = Dense(channel,
                             kernel_initializer='he_normal',
                             use_bias=True,
                             bias_initializer='zeros')
    avg_pool = GlobalAveragePooling2D()(input_feature)    
    avg_pool = Reshape((1,1,channel))(avg_pool)
    assert avg_pool.shape[1:] == (1,1,channel)
    avg_pool = shared_layer_one(avg_pool)
    assert avg_pool.shape[1:] == (1,1,channel//ratio)
    avg_pool = shared_layer_two(avg_pool)
    assert avg_pool.shape[1:] == (1,1,channel)
    
    max_pool = GlobalMaxPooling2D()(input_feature)
    max_pool = Reshape((1,1,channel))(max_pool)
    assert max_pool.shape[1:] == (1,1,channel)
    max_pool = shared_layer_one(max_pool)
    assert max_pool.shape[1:] == (1,1,channel//ratio)
    max_pool = shared_layer_two(max_pool)
    assert max_pool.shape[1:] == (1,1,channel)
    
    cbam_feature = Add()([avg_pool,max_pool])
    cbam_feature = Activation('sigmoid')(cbam_feature)
    
    if K.image_data_format() == "channels_first":
        cbam_feature = Permute((3, 1, 2))(cbam_feature)
    return multiply([input_feature, cbam_feature])

def spatial_attention(input_feature):
    kernel_size = 7
    
    if K.image_data_format() == "channels_first":
        channel = input_feature.shape[1]
        cbam_feature = Permute((2,3,1))(input_feature)
    else:
        channel = input_feature.shape[-1]
        cbam_feature = input_feature

    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)
    assert avg_pool.shape[-1] == 1
    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)
    assert max_pool.shape[-1] == 1
    concat = Concatenate(axis=3)([avg_pool, max_pool])
    assert concat.shape[-1] == 2
    cbam_feature = Conv2D(filters = 1,
                    kernel_size=kernel_size,
                    strides=1,
                    padding='same',
                    activation='sigmoid',
                    kernel_initializer='he_normal',
                    use_bias=False)(concat)	
    assert cbam_feature.shape[-1] == 1
    if K.image_data_format() == "channels_first":
        cbam_feature = Permute((3, 1, 2))(cbam_feature)
    
    return multiply([input_feature, cbam_feature])


def CNN_CBAMAtt(input_shape, n_classes, acf):
    str1='cbam_att'
    inp = Input(input_shape)
    # inp = layers.Input(shape=(input_shape))
    # x1 = layers.Resizing(img_rows, img_cols)(inp)
    # x2 = layers.Rescaling(1./255)(x1)
    x2 = inp
    x3 = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', 
                       padding = 'same', input_shape=(input_shape))(x2)
    x4 = cbam(x3)
    x5 = layers.BatchNormalization(axis=-1)(x4)
    x6 = layers.MaxPool2D(pool_size=(2, 2))(x5)
    x7 = layers.Conv2D(filters=64, kernel_size=(3, 3), 
                       activation='relu', padding = 'same')(x6)
    x8 = cbam(x7)
    x9 = layers.BatchNormalization(axis=-1)(x8)
    x10 = layers.MaxPool2D(pool_size=(2, 2))(x9)
    x11 = layers.Conv2D(filters=128, kernel_size=(3, 3), 
                        activation='relu', padding = 'same')(x10)
    x12 = cbam(x11)
    x13 = layers.BatchNormalization(axis=-1)(x12)
    x14 = layers.MaxPool2D(pool_size=(2, 2))(x13)
    x15 = layers.Conv2D(filters=256, kernel_size=(3, 3), 
                          activation='relu', padding = 'same')(x14)
    x16 = cbam(x15)
    x17 = layers.BatchNormalization(axis=-1)(x16)
    x18 = layers.MaxPool2D(pool_size=(2, 2))(x17)
    y1 = layers.Flatten()(x18)
    y2 = layers.Dense(300, activation='relu')(y1)
    y3 = layers.Dense(150, activation='relu')(y2)
    y4 = layers.Dropout(0.25)(y3)
    y = layers.Dense(4, activation='sigmoid')(y4)   
    
    model_CBAM = tf.keras.Model(inp, y)
    model=model_CBAM
    return model, str1  


def CNN_LSTM_Att2(input_shape, n_classes, acf):
    str1='cnn_lstm_selfatt'
    inp = Input(input_shape)
    x = L.Conv2D(32, (3, 3), activation=acf, padding='same')(inp)
    # x = L.BatchNormalization()(x)
    x = L.Conv2D(32, (3, 3), activation=acf, padding='same')(inp)
    # x = L.BatchNormalization()(x)
    x = L.MaxPooling2D(pool_size=(2, 2))(x)
    x = L.Dropout(0.25)(x)

    x = L.Conv2D(64, (3, 3), activation=acf, padding='same')(inp)
    # x = L.BatchNormalization()(x)
    x = L.Conv2D(64, (3, 3), activation=acf, padding='same')(inp)
    # x = L.BatchNormalization()(x)
    x = L.MaxPooling2D(pool_size=(2, 2))(x)
    x = L.Dropout(0.25)(x)

    x = L.Conv2D(128, (3, 3), activation=acf, padding='same')(inp)
    # x = L.BatchNormalization()(x)
    x = L.Conv2D(128, (3, 3), activation=acf, padding='same')(inp)
    # x = L.BatchNormalization()(x)
    x = L.MaxPooling2D(pool_size=(2, 2))(x)
    x = L.Dropout(0.25)(x)
    
    x = L.Conv2D(1, (3, 3), activation=acf, padding='same')(x)
    # x = L.BatchNormalization()(x)
    # print('zzzzz  x shape====', x.shape)
    # x = Reshape((125, 80)) (x)
    # keras.backend.squeeze(x, axis)
    x = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)
    # print('zz2  x shape====', x.shape)

    x = L.Bidirectional(LSTM(256, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]
    x = L.Bidirectional(LSTM(128, return_sequences=True))(x)  # [b_s, seq_len, vec_dim]
    xFirst = L.Lambda(lambda q: q[:, -1])(x)  # [b_s, vec_dim]
    query = L.Dense(256)(xFirst)

    # dot product attention
    attScores = L.Dot(axes=[1, 2])([query, x])
    attScores = L.Softmax(name='attSoftmax')(attScores)  # [b_s, seq_len]
   
    # rescale sequence
    attVector = L.Dot(axes=[1, 1])([attScores, x])  # [b_s, vec_dim]
    print('zz3  att shape====', attVector.shape)
    print(attVector.shape[0],attVector.shape[1])
    # x = L.Flatten()(attVector)
    # print(x.shape[0],x.shape[1])
    x = L.Dense(512, activation=acf)(attVector)
    x = Dropout(0.5)(x)
    # x = L.Dense(32)(x)
    x = L.Dense(n_classes, activation='softmax', name='output')(x)

    model = Model(inp, x)

    return model, str1            



def mini_nvidia_model(input_shape, n_classes, acf):
    str1='m_nv'    
    model = Sequential()
    model.add(Conv2D(32, (3, 3), activation=acf, input_shape=input_shape))
    model.add(Conv2D(64, (3, 3), activation=acf))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(128, activation=acf))
    model.add(Dropout(0.5))
    model.add(Dense(n_classes, activation='softmax'))
    return model,str1


# use elu not relu 
def nvidia_model(input_shape, n_classes, acf):
    str1='nv'    

    model = Sequential()
    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))
    model.add(Activation(acf))
    model.add(Conv2D(32, (3, 3)))
    model.add(Activation(acf))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    model.add(Conv2D(64, (3, 3), padding='same'))
    model.add(Activation(acf))
    model.add(Conv2D(64, (3, 3)))
    model.add(Activation(acf))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    model.add(Flatten())
    model.add(Dense(512))
    model.add(Activation(acf))
    model.add(Dropout(0.5))
    model.add(Dense(n_classes))
    model.add(Activation('softmax'))
#    model.add(Dense(1))
    return model,str1
    
def sVGG(input_shape, n_classes, acf):
    str1='sVGG'    
    chanDim = -1
    model = Sequential()
    # first CONV => RELU => CONV => RELU => POOL layer set
    model.add(Conv2D(32, (3, 3), padding = "same", input_shape=input_shape))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(32, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    # second CONV => Relu => CONV => Relu => POOL layer set
    model.add(Conv2D(64, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(64, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    # third CONV => Relu => CONV => Relu => POOL layer set
    model.add(Conv2D(128, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(128, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    

    # first (and only) set of FC => Relu layers
    model.add(Flatten())
    model.add(Dense(512))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Dropout(0.5))
    
#     softmax classifier
    model.add(Dense(n_classes, activation='softmax'))    
 
    return model,str1

def VGG16(input_shape, n_classes, acf):

## or use VGGNet    
    str1='VGG16'
    chanDim = -1
    model = Sequential()
    # first CONV => RELU => CONV => RELU => POOL layer set
    model.add(Conv2D(64, (3, 3), padding = "same", input_shape=input_shape))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(64, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    # second CONV => Relu => CONV => Relu => POOL layer set
    model.add(Conv2D(128, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(128, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    # third CONV => Relu => CONV => Relu => POOL layer set
    model.add(Conv2D(256, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(256, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(256, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    # model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    # model.add(MaxPooling2D(pool_size=(2, 2)))

    # first (and only) set of FC => Relu layers
    model.add(Flatten())
    model.add(Dense(512))
    model.add(Activation("relu"))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))
    
    model.add(Dense(256))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Dropout(0.5))

    # softmax classifier
    model.add(Dense(n_classes, activation='softmax'))
    return model, str1

def VGG19(input_shape, n_classes, acf):

## or use VGGNet    
    str1='VGG19'
    chanDim = -1
    model = Sequential()
    # first CONV => RELU => CONV => RELU => POOL layer set
    model.add(Conv2D(64, (3, 3), padding = "same", input_shape=input_shape))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(64, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    # second CONV => Relu => CONV => Relu => POOL layer set
    model.add(Conv2D(128, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(128, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    # third CONV => Relu => CONV => Relu => POOL layer set
    model.add(Conv2D(256, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(256, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(256, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(256, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    # model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Conv2D(512, (3, 3), padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    # model.add(MaxPooling2D(pool_size=(2, 2)))

    # first (and only) set of FC => Relu layers
    model.add(Flatten())
    model.add(Dense(512))
    model.add(Activation("relu"))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))
    
    model.add(Dense(256))
    model.add(Activation("relu"))
    model.add(BatchNormalization(axis=chanDim))
    model.add(Dropout(0.5))

    # softmax classifier
    model.add(Dense(n_classes, activation='softmax'))
    return model, str1

            
"""
ResNet v1
[a] Deep Residual Learning for Image Recognition
https://arxiv.org/pdf/1512.03385.pdf

ResNet v2
[b] Identity Mappings in Deep Residual Networks
https://arxiv.org/pdf/1603.05027.pdf
"""

#import keras
#from keras.layers import Dense, Conv2D, BatchNormalization, Activation
#from keras.layers import AveragePooling2D, Input, Flatten
#from keras.optimizers import Adam
#from keras.callbacks import ModelCheckpoint, LearningRateScheduler
#from keras.callbacks import ReduceLROnPlateau
#from keras.preprocessing.image import ImageDataGenerator
#from keras.regularizers import l2
#from keras import backend as K
#from keras.models import Model
#import numpy as np
#import os
#from keras.optimizers import Adam

def lr_schedule(epoch):
    """Learning Rate Schedule

    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.
    Called automatically every epoch as part of callbacks during training.

    # Arguments
        epoch (int): The number of epochs

    # Returns
        lr (float32): learning rate
    """
    lr = 1e-3
    if epoch > 180:
        lr *= 0.5e-3
    elif epoch > 160:
        lr *= 1e-3
    elif epoch > 120:
        lr *= 1e-2
    elif epoch > 80:
        lr *= 1e-1
    print('Learning rate: ', lr)
    return lr

def resnet_layer(inputs,
                 activation,
                 num_filters=16,
                 kernel_size=3,
                 strides=1,
                 batch_normalization=True,
                 conv_first=True):
    """2D Convolution-Batch Normalization-Activation stack builder

    # Arguments
        inputs (tensor): input tensor from input image or previous layer
        num_filters (int): Conv2D number of filters
        kernel_size (int): Conv2D square kernel dimensions
        strides (int): Conv2D square stride dimensions
        activation (string): activation name
        batch_normalization (bool): whether to include batch normalization
        conv_first (bool): conv-bn-activation (True) or
            bn-activation-conv (False)

    # Returns
        x (tensor): tensor as input to the next layer
    """
    conv = Conv2D(num_filters,
                  kernel_size=kernel_size,
                  strides=strides,
                  padding='same',
                  kernel_initializer='he_normal',
                  kernel_regularizer=l2(1e-4))

    x = inputs
    if conv_first:
        x = conv(x)
        if batch_normalization:
            x = BatchNormalization()(x)
        if activation is not None:
            x = Activation(activation)(x)
    else:
        if batch_normalization:
            x = BatchNormalization()(x)
        if activation is not None:
            x = Activation(activation)(x)
        x = conv(x)
    return x

def resnet_v1(input_shape, n_classes, acf):
    """ResNet Version 1 Model builder [a]

    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU
    Last ReLU is after the shortcut connection.
    At the beginning of each stage, the feature map size is halved (downsampled)
    by a convolutional layer with strides=2, while the number of filters is
    doubled. Within each stage, the layers have the same number filters and the
    same number of filters.
    Features maps sizes:
    stage 0: 32x32, 16
    stage 1: 16x16, 32
    stage 2:  8x8,  64
    The Number of parameters is approx the same as Table 6 of [a]:
    ResNet20 0.27M
    ResNet32 0.46M
    ResNet44 0.66M
    ResNet56 0.85M
    ResNet110 1.7M

    # Arguments
        input_shape (tensor): shape of input image tensor
        depth (int): number of core convolutional layers
        num_classes (int): number of classes (CIFAR10 has 10)

    # Returns
        model (Model): Keras model instance
    """
    str1='ResNet v1'
    n = 9
    depth = n * 6 + 2
    if (depth - 2) % 6 != 0:
        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')
    # Start model definition.
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6)
#    input_shape=(66, 200, 3)
    input_shape=input_shape
    inputs = Input(shape=input_shape)
    x = resnet_layer(inputs=inputs,activation=acf)
    # Instantiate the stack of residual units
    for stack in range(3):
        for res_block in range(num_res_blocks):
            strides = 1
            if stack > 0 and res_block == 0:  # first layer but not first stack
                strides = 2  # downsample
            y = resnet_layer(inputs=x,
                             num_filters=num_filters,
                             strides=strides,
                             activation=acf)
            y = resnet_layer(inputs=y,
                             num_filters=num_filters,
                             activation=None)
            if stack > 0 and res_block == 0:  # first layer but not first stack
                # linear projection residual shortcut connection to match
                # changed dims
                x = resnet_layer(inputs=x,
                                 num_filters=num_filters,
                                 kernel_size=1,
                                 strides=strides,
                                 activation=None,
                                 batch_normalization=False)
            x = keras.layers.add([x, y])
            x = Activation(acf)(x)
        num_filters *= 2

    # Add classifier on top.
    # v1 does not use BN after last shortcut connection-ReLU
#    x = AveragePooling2D(pool_size=8)(x)
    x = AveragePooling2D(pool_size=2)(x)
    y = Flatten()(x)
    outputs = Dense(n_classes,
                    activation='softmax',
                    kernel_initializer='he_normal')(y)

    # Instantiate model.
#    model = Model(inputs=inputs, outputs=outputs)
    
    
#    outputs = Dense(1)(y)
    # Instantiate model.
    
    model = Model(inputs=inputs, outputs=outputs)

#    # initiate RMSprop optimizer
#    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)
#    
#    # Let's train the model using RMSprop
#    model.compile(loss='categorical_crossentropy',
#                  optimizer=opt,
#                  metrics=['accuracy'])    
    return model, str1


def resnet_v2(input_shape, n_classes, acf, n1):
    """ResNet Version 2 Model builder [b]
    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as
    bottleneck layer
    First shortcut connection per layer is 1 x 1 Conv2D.
    Second and onwards shortcut connection is identity.
    At the beginning of each stage, the feature map size is halved (downsampled)
    by a convolutional layer with strides=2, while the number of filter maps is
    doubled. Within each stage, the layers have the same number filters and the
    same filter map sizes.
    Features maps sizes:
    conv1  : 32x32,  16
    stage 0: 32x32,  64
    stage 1: 16x16, 128
    stage 2:  8x8,  256

    # Arguments
        input_shape (tensor): shape of input image tensor
        depth (int): number of core convolutional layers
        num_classes (int): number of classes (CIFAR10 has 10)

    # Returns
        model (Model): Keras model instance
    """

    str1='ResNet v2'
    n = n1
    depth = n * 9 + 2
    # Model parameter
    # ----------------------------------------------------------------------------
    #           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch
    # Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti
    #           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)
    # ----------------------------------------------------------------------------
    # ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)
    # ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)
    # ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)
    # ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)
    # ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)
    # ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)
    # ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)
    # ---------------------------------------------------------------------------
    
    # Model version
    # Original paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)
    # Computed depth from supplied model parameter n

    if (depth - 2) % 9 != 0:
        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')
    # Start model definition.
    num_filters_in = 16
    num_res_blocks = int((depth - 2) / 9)

    inputs = Input(shape=input_shape)
    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths
    x = resnet_layer(inputs=inputs,
                     num_filters=num_filters_in,
                     conv_first=True,
                     activation=acf)
    # Instantiate the stack of residual units
    for stage in range(3):
        for res_block in range(num_res_blocks):
            activation = acf
            batch_normalization = True
            strides = 1
            if stage == 0:
                num_filters_out = num_filters_in * 4
                if res_block == 0:  # first layer and first stage
                    activation = None
                    batch_normalization = False
            else:
                num_filters_out = num_filters_in * 2
                if res_block == 0:  # first layer but not first stage
                    strides = 2    # downsample

            # bottleneck residual unit
            y = resnet_layer(inputs=x,
                             num_filters=num_filters_in,
                             kernel_size=1,
                             strides=strides,
                             activation=activation,
                             batch_normalization=batch_normalization,
                             conv_first=False)
            y = resnet_layer(inputs=y,
                             activation=activation,
                             num_filters=num_filters_in,
                             conv_first=False)
            y = resnet_layer(inputs=y,
                             activation=activation,
                             num_filters=num_filters_out,
                             kernel_size=1,
                             conv_first=False)
            if res_block == 0:
                # linear projection residual shortcut connection to match
                # changed dims
                x = resnet_layer(inputs=x,
                                 num_filters=num_filters_out,
                                 kernel_size=1,
                                 strides=strides,
                                 activation=None,
                                 batch_normalization=False)
            x = keras.layers.add([x, y])

        num_filters_in = num_filters_out

    # Add classifier on top.
    # v2 has BN-ReLU before Pooling
    x = BatchNormalization()(x)
    x = Activation(acf)(x)
#    x = AveragePooling2D(pool_size=8)(x)
    x = AveragePooling2D(pool_size=2)(x)
    y = Flatten()(x)
    outputs = Dense(n_classes, activation='softmax',
                    kernel_initializer='he_normal')(y)
#    # Instantiate model.
#    model = Model(inputs=inputs, outputs=outputs)
#    outputs = Dense(1)(y)
    # Instantiate model
    model = Model(inputs=inputs, outputs=outputs)
#    # initiate RMSprop optimizer
#    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)

#    # Let's train the model using RMSprop
#    model.compile(loss='categorical_crossentropy',
#                  optimizer=opt,
#                  metrics=['accuracy'])
    return model, str1







#########################
#########################
## confusion matrices
#########################
def get_new_fig(fn, figsize=[9,9]):
    """ Init graphics """
    plt.clf()    
    fig1 = plt.figure(fn, figsize)
    ax1 = fig1.gca()   #Get Current Axis
    ax1.cla() # clear existing plot
    return fig1, ax1


def configcell_text_and_colors(array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0):
    """
      config cell text and colors
      and return text elements to add and to dell
      @TODO: use fmt
    """
    text_add = []; text_del = [];
    cell_val = array_df[lin][col]
    tot_all = array_df[-1][-1]
    per = (float(cell_val) / tot_all) * 100
    curr_column = array_df[:,col]
    ccl = len(curr_column)

    #last line  and/or last column
    if(col == (ccl - 1)) or (lin == (ccl - 1)):
        #tots and percents
        if(cell_val != 0):
            if(col == ccl - 1) and (lin == ccl - 1):
                tot_rig = 0
                for i in range(array_df.shape[0] - 1):
                    tot_rig += array_df[i][i]
                per_ok = (float(tot_rig) / cell_val) * 100
            elif(col == ccl - 1):
                tot_rig = array_df[lin][lin]
                per_ok = (float(tot_rig) / cell_val) * 100
            elif(lin == ccl - 1):
                tot_rig = array_df[col][col]
                per_ok = (float(tot_rig) / cell_val) * 100
            per_err = 100 - per_ok
        else:
            per_ok = per_err = 0

        per_ok_s = ['%.2f%%'%(per_ok), '100%'] [per_ok == 100]

        #text to DEL
        text_del.append(oText)

        #text to ADD
        font_prop = fm.FontProperties(weight='bold', size=fz)
        text_kwargs = dict(color='w', ha="center", va="center", gid='sum', fontproperties=font_prop)
        lis_txt = ['%d'%(cell_val), per_ok_s, '%.2f%%'%(per_err)]
        lis_kwa = [text_kwargs]
        dic = text_kwargs.copy(); dic['color'] = 'g'; lis_kwa.append(dic);
        dic = text_kwargs.copy(); dic['color'] = 'r'; lis_kwa.append(dic);
        lis_pos = [(oText._x, oText._y-0.3), (oText._x, oText._y), (oText._x, oText._y+0.3)]
        for i in range(len(lis_txt)):
            newText = dict(x=lis_pos[i][0], y=lis_pos[i][1], text=lis_txt[i], kw=lis_kwa[i])
            #print 'lin: %s, col: %s, newText: %s' %(lin, col, newText)
            text_add.append(newText)
        #print '\n'

        #set background color for sum cells (last line and last column)
        carr = [0.27, 0.30, 0.27, 1.0]
        if(col == ccl - 1) and (lin == ccl - 1):
            carr = [0.17, 0.20, 0.17, 1.0]
        facecolors[posi] = carr

    else:
        if(per > 0):
            txt = '%s\n%.2f%%' %(cell_val, per)
        else:
            if(show_null_values == 0):
                txt = ''
            elif(show_null_values == 1):
                txt = '0'
            else:
                txt = '0\n0.0%'
        oText.set_text(txt)

        #main diagonal
        if(col == lin):
            #set color of the textin the diagonal to white
            oText.set_color('w')
            # set background color in the diagonal to blue
            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]
        else:
            oText.set_color('r')

    return text_add, text_del

def insert_totals(df_cm):
    """ insert total column and line (the last ones) """
    sum_col = []
    for c in df_cm.columns:
        sum_col.append( df_cm[c].sum() )
    sum_lin = []
    for item_line in df_cm.iterrows():
        sum_lin.append( item_line[1].sum() )
    df_cm['sum_lin'] = sum_lin
    sum_col.append(np.sum(sum_lin))
    df_cm.loc['sum_col'] = sum_col
    #print ('\ndf_cm:\n', df_cm, '\n\b\n')

def pretty_plot_confusion_matrix(df_cm, annot=True, cmap="Oranges", fmt='.2f', fz=11,
      lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='y'):
    """
      print conf matrix with default layout (like matlab)
      params:
        df_cm          dataframe (pandas) without totals
        annot          print text in each cell
        cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:
        fz             fontsize
        lw             linewidth
        pred_val_axis  where to show the prediction values (x or y axis)
                        'col' or 'x': show predicted values in columns (x axis) instead lines
                        'lin' or 'y': show predicted values in lines   (y axis)
    """
    if(pred_val_axis in ('col', 'x')):
        xlbl = 'Predicted'
        ylbl = 'Actual'
    else:
        xlbl = 'Actual'
        ylbl = 'Predicted'
        df_cm = df_cm.T

    # create "Total" column
    insert_totals(df_cm)

    #this is for print allways in the same window
    fig, ax1 = get_new_fig('Conf matrix default', figsize)

    #thanks for seaborn
    ax = sn.heatmap(df_cm, annot=annot, annot_kws={"size": fz}, linewidths=lw, ax=ax1,
                    cbar=cbar, cmap=cmap, linecolor='w', fmt=fmt)

    #set ticklabels rotation
    ax.set_xticklabels(ax.get_xticklabels(), rotation = 45, fontsize = 10)
    ax.set_yticklabels(ax.get_yticklabels(), rotation = 25, fontsize = 10)

    # Turn off all the ticks
    for t in ax.xaxis.get_major_ticks():
        t.tick1On = False
        t.tick2On = False
    for t in ax.yaxis.get_major_ticks():
        t.tick1On = False
        t.tick2On = False

    #face colors list
    quadmesh = ax.findobj(QuadMesh)[0]
    facecolors = quadmesh.get_facecolors()

    #iter in text elements
    array_df = np.array( df_cm.to_records(index=False).tolist() )
    text_add = []; text_del = [];
    posi = -1 #from left to right, bottom to top.
    for t in ax.collections[0].axes.texts: #ax.texts:
        pos = np.array( t.get_position()) - [0.5,0.5]
        lin = int(pos[1]); col = int(pos[0]);
        posi += 1
        #print ('>>> pos: %s, posi: %s, val: %s, txt: %s' %(pos, posi, array_df[lin][col], t.get_text()))

        #set text
        txt_res = configcell_text_and_colors(array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values)

        text_add.extend(txt_res[0])
        text_del.extend(txt_res[1])

    #remove the old ones
    for item in text_del:
        item.remove()
    #append the new ones
    for item in text_add:
        ax.text(item['x'], item['y'], item['text'], **item['kw'])

    #titles and legends
    ax.set_title('Confusion matrix')
    ax.set_xlabel(xlbl)
    ax.set_ylabel(ylbl)
    plt.tight_layout()  #set layout slim
#    plt.show()
    plt.savefig(head1+'\\conf_mat_'+tail1+'_cnn.png')


def plot_confusion_matrix_from_data(y_test, predictions, columns=None, annot=True, cmap="Oranges",
      fmt='.2f', fz=11, lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='lin'):
    """
        plot confusion matrix function with y_test (actual values) and predictions (predic),
        whitout a confusion matrix yet
    """
    from sklearn.metrics import confusion_matrix
    from pandas import DataFrame

    #data
    if(not columns):
        #labels axis integer:
        ##columns = range(1, len(np.unique(y_test))+1)
        #labels axis string:
        from string import ascii_uppercase
        columns = ['class %s' %(i) for i in list(ascii_uppercase)[0:len(np.unique(y_test))]]
        columns=['A','H','N','S']
        columns=labels

    confm = confusion_matrix(y_test, predictions)
    cmap = 'Oranges';
    fz = 11;
    figsize=[9,9];
    show_null_values = 2
    df_cm = DataFrame(confm, index=columns, columns=columns)
    pretty_plot_confusion_matrix(df_cm, fz=fz, cmap=cmap, figsize=figsize, show_null_values=show_null_values, pred_val_axis=pred_val_axis)
#
#TEST functions
def _test_cm():
    #test function with confusion matrix done
    array = np.array( [[13,  0,  1,  0,  2,  0],
                       [ 0, 50,  2,  0, 10,  0],
                       [ 0, 13, 16,  0,  0,  3],
                       [ 0,  0,  0, 13,  1,  0],
                       [ 0, 40,  0,  1, 15,  0],
                       [ 0,  0,  0,  0,  0, 20]])
    #get pandas dataframe
    df_cm = DataFrame(array, index=range(1,7), columns=range(1,7))
    #colormap: see this and choose your more dear
    cmap = 'PuRd'
    pretty_plot_confusion_matrix(df_cm, cmap=cmap)
#
def _test_data_class(y_test1, y_pred1):
    """ test function with y_test (actual values) and predictions (predic) """
    #data
#    y_test = np.array([1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5])
#    predic = np.array([1,2,4,3,5, 1,2,4,3,5, 1,2,3,4,4, 1,4,3,4,5, 1,2,4,4,5, 1,2,4,4,5, 1,2,4,4,5, 1,2,4,4,5, 1,2,3,3,5, 1,2,3,3,5, 1,2,3,4,4, 1,2,3,4,1, 1,2,3,4,1, 1,2,3,4,1, 1,2,4,4,5, 1,2,4,4,5, 1,2,4,4,5, 1,2,4,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5, 1,2,3,4,5])
    y_test = y_test1
    predic=y_pred1
    """
      Examples to validate output (confusion matrix plot)
        actual: 5 and prediction 1   >>  3
        actual: 2 and prediction 4   >>  1
        actual: 3 and prediction 4   >>  10
    """
    columns = []
    annot = True;
    cmap = 'Oranges';
    fmt = '.2f'
    lw = 0.5
    cbar = False
    show_null_values = 2
    pred_val_axis = 'y'
    #size::
    fz = 12;
    figsize = [9,9];
    if(len(y_test) > 10):
        fz=9; figsize=[14,14];
    plot_confusion_matrix_from_data(y_test, predic, columns,
      annot, cmap, fmt, fz, lw, cbar, figsize, show_null_values, pred_val_axis)


def precision(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision


def recall(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall


def fscore(y_true, y_pred):
    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:
        return 0

    p = precision(y_true, y_pred)
    r = recall(y_true, y_pred)
    f_score = 2 * (p * r) / (p + r + K.epsilon())
    return f_score